# ğŸš€ Observability Stack â€” End-to-End Monitoring & Self-Healing Demo

A complete containerized observability demo showing **how modern production systems monitor, alert, and auto-heal**.  
This stack combines **Flask + PostgreSQL + Prometheus + Grafana + Alertmanager + a Python Alert Bot** â€” all orchestrated with Docker Compose.

---

## ğŸŒ Overview

This project simulates a **real-world production environment** with:
- A web API (Flask)
- A database (PostgreSQL)
- A background worker
- Metrics collection (Prometheus)
- System & endpoint exporters
- Visualization (Grafana)
- Alerting (Alertmanager)
- Automated remediation (Python alert bot)

Together they form a **complete observability pipeline**:
> Metrics âœ Dashboards âœ Alerts âœ Auto-actions

---

## ğŸ§© Why these components?

| Component | Role | Why Chosen |
|------------|------|------------|
| **Docker & Compose** | Orchestrates all containers. | Reproducible, realistic multi-service setup. |
| **Flask (API)** | Serves `/health`, `/transactions`, `/metrics`. | Lightweight, easy to instrument. |
| **PostgreSQL** | Transaction store for API + worker. | Common production DB, demonstrates real load. |
| **Worker (Python)** | Simulates background batch inserts. | Mimics cron / async jobs in production. |
| **Prometheus** | Scrapes & stores metrics. | Industry standard for metrics monitoring. |
| **Node Exporter** | Exposes host CPU/memory metrics. | System-level observability. |
| **Blackbox Exporter** | Probes API endpoints externally. | Simulates uptime checks. |
| **Grafana** | Dashboards & visualization. | Friendly, flexible front-end for metrics. |
| **Alertmanager** | Routes alerts from Prometheus. | Notification management (Slack/email/webhook). |
| **Alert Bot (Python)** | Receives webhooks, performs auto-remediation. | Demonstrates self-healing automation. |

---

## ğŸ§  Architecture

 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Flask  API  â”‚â”€â”€â”
 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚ exposes /metrics
        â”‚          â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”‚
 â”‚ PostgreSQL  â”‚<â”€â”€â”˜  (store transactions)
 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
 â”‚  Worker     â”‚ (batch inserts)
 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚ metrics
 â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚    Prometheus      â”‚  â† scrapes exporters
 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚ alerts
 â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   Alertmanager     â”‚  â†’ Slack / Alert Bot
 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
 â”‚ Alert Bot   â”‚  (restart/scale/log)
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
   Grafana  â†  visualizes everything

   ---

## âš™ï¸ Folder Structure

Observability-Stack/
â”œâ”€ api/
â”‚  â”œâ”€ app.py
â”‚  â”œâ”€ requirements.txt
â”‚  â””â”€ Dockerfile
â”œâ”€ worker/
â”‚  â”œâ”€ worker.py
â”‚  â”œâ”€ requirements.txt
â”‚  â””â”€ Dockerfile
â”œâ”€ alert_bot/
â”‚  â”œâ”€ alert_bot.py
â”‚  â”œâ”€ requirements.txt
â”‚  â””â”€ Dockerfile
â”œâ”€ prometheus/
â”‚  â”œâ”€ prometheus.yml
â”‚  â””â”€ alert.rules.yml
â”œâ”€ alertmanager/
â”‚  â””â”€ config.yml
â”œâ”€ db/
â”‚  â””â”€ init.sql
â”œâ”€ docker-compose.yml
â””â”€ README.md

---

## ğŸƒâ€â™‚ï¸ Quick Start

1. **Clone & enter**
   ```bash
   git clone https://github.com/yourname/observability-stack.git
   cd observability-stack
2. **Copy Example env**
   cp .env.example .env

# Fill Slack webhook or email creds (optional)

3. **Run Everything**
    docker compose up -d --build

4. **Check Services**
    Service  -- URL
    Flask API
    http://localhost:8000/health
    Prometheus
    http://localhost:9090
    Grafana
    http://localhost:3000 (admin / admin)
    Alertmanager
    http://localhost:9093

5. **Generating Traffic**
    for i in {1..20}; do curl -s http://localhost:8000/health > /dev/null; sleep 1; done (In your terminal / CLI)

ğŸ“Š Dashboards & Metrics
	â€¢	API latency (p95) â†’ histogram_quantile(0.95, sum(rate(flask_http_request_duration_seconds_bucket[5m])) by (le))
	â€¢	Error rate â†’ rate(flask_http_request_exceptions_total[5m])
	â€¢	System CPU / Memory â†’ from Node Exporter.
	â€¢	Uptime probe â†’ probe_success from Blackbox Exporter.

â¸»

ğŸš¨ Alerting Rules
    Alert -- Trigger -- Action

    APIHighLatency -- p95 latency > 200 ms for 1 m -- Slack + Alert Bot
    APIErrorRateHigh -- error rate > 5 % for 5 m -- lack + Alert Bot

ğŸ¤– Automation (Alert Bot)

When Alertmanager sends a webhook:
	â€¢	Parses alert labels.
	â€¢	Runs actions:
	â€¢	docker restart flask_api
	â€¢	docker compose up --scale worker=3
	â€¢	Logs the event into incident_log.jsonl.

You can simulate manually:
    curl -XPOST -H "Content-Type: application/json" \
    -d '{"alerts":[{"labels":{"alertname":"APIHighLatency","severity":"critical"}}]}' \
    -- > http://localhost:5001/alert

ğŸ” Simulating Production
	â€¢	Multiple services: API, DB, worker mimic microservices.
	â€¢	Database I/O: worker generates realistic DB load.
	â€¢	Exporters: monitor system + external health like real production.
	â€¢	Alerting + Auto-Remediation: shows a complete observability â†’ alert â†’ action loop.
	â€¢	Docker Compose network: replicates production service discovery.

â¸»

ğŸ” Best Practices
    Area -- Good Practice
    Secrets -- Never commit .env with real keys.
    Grafana -- Change default admin password.
    Alert Bot -- Donâ€™t mount /var/run/docker.sock in prod.
    Metrics -- Avoid high-cardinality labels.
    Alerts -- Use for: to prevent flapping; group similar alerts.

ğŸ§° Troubleshooting
    Issue -- Likely Cause --Fix
Mount error for prometheus.yml -- Wrong host path / spaces in folder name -- Remove spaces, verify file path.
API down in Prometheus -- Service name mismatch -- Ensure api in docker-compose matches Prometheus target.
Worker fails to connect DB -- DB not yet ready -- Healthcheck + retry loop.
â€œNo alert groups foundâ€ -- No active alerts -- Trigger latency/error manually.

ğŸ Clean Up
    docker compose down -v
    docker system prune -af --volumes

